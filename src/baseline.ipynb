{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/home/houruijie/traffic/traffic/src'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#encoding:utf-8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "plt.figure(figsize=(15,18))\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "%matplotlib inline\n",
    "predict_dir_path = '/home/houruijie/traffic/traffic/data/predict_data/'\n",
    "train_dir_path = '/home/houruijie/traffic/traffic/data/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def concat_goods_counts():\n",
    "    #将读取的第一个CSV文件写入合并后的文件保存\n",
    "    file_list = os.listdir(train_dir_path + '货量表/')\n",
    "    df = pd.read_csv(train_dir_path+ '货量表/' + file_list[0]) \n",
    "    df.to_csv(train_dir_path + 'goods_counts.csv',index=False)\n",
    "    for i in range(1,len(file_list)):\n",
    "        df = pd.read_csv(train_dir_path + '货量表/' + file_list[i])\n",
    "        df.to_csv(train_dir_path + 'goods_counts.csv',index=False, header=False, mode='a+')\n",
    "concat_goods_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def concat_call_logs():\n",
    "    #将读取的第一个CSV文件写入合并后的文件保存\n",
    "    file_list = os.listdir(train_dir_path + '司机电话日志/')\n",
    "    df = pd.read_csv(train_dir_path+ '司机电话日志/' + file_list[0]) \n",
    "    df.to_csv(train_dir_path + 'call_logs.csv',index=False)\n",
    "    for i in range(1,len(file_list)):\n",
    "        df = pd.read_csv(train_dir_path + '司机电话日志/' + file_list[i])\n",
    "        df.to_csv(train_dir_path + 'call_logs.csv',index=False, header=False, mode='a+')\n",
    "driver_call_logs = pd.read_csv(train_dir_path + 'call_logs.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 司机画像\n",
    "driver_portrait = pd.read_csv(train_dir_path + '司机画像.csv')\n",
    "# 货主画像\n",
    "shipper_portrait = pd.read_csv(train_dir_path+'货主画像.csv')\n",
    "# 城市公路距离\n",
    "city_way_distance = pd.read_csv(train_dir_path + '城市公路距离记录.csv')\n",
    "# 城市天气记录\n",
    "city_weather_history = pd.read_csv(train_dir_path + '城市天气记录.csv', encoding='gbk')\n",
    "city_weather_history.date = pd.to_datetime(city_weather_history['date'], format='%Y-%m-%d', errors='ignore')\n",
    "# 货量表\n",
    "goodscounts = pd.read_csv(train_dir_path + 'goods_counts.csv')\n",
    "goodscounts.day = pd.to_datetime(goodscounts['day'], format='%Y%m%d', errors='ignore')\n",
    "# 司机电话日志\n",
    "driver_call_logs = pd.read_csv(train_dir_path + 'call_logs.csv' )\n",
    "# 司机量表\n",
    "driver_counts = pd.read_csv(train_dir_path + 'driver_counts.csv')\n",
    "driver_counts.day = pd.to_datetime(driver_counts['day'], format='%Y%m%d', errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# merge weather data\n",
    "goods_counts_add_weather = goodscounts.merge(city_weather_history, left_on=['city', 'day'], right_on=['code', 'date'],)\n",
    "driver_counts_add_weather = driver_counts.merge(city_weather_history, left_on=['city', 'day'], right_on=['code', 'date'])\n",
    "goods_counts_add_weather['is_train'] = 1\n",
    "driver_counts_add_weather['is_train'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 预测数据\n",
    "# predict = pd.read_csv(predict_dir_path + 'predict.csv', header=None)\n",
    "weather = pd.read_csv(predict_dir_path + '天气数据.csv', encoding='gbk')\n",
    "weather.date = pd.to_datetime(weather['date'], format='%Y-%m-%d', errors='ignore')\n",
    "# predict_sample = pd.read_csv(predict_dir_path + 'predict_sample.csv', header=None)\n",
    "predict_data = pd.read_csv(predict_dir_path + 'sample.csv')\n",
    "predict_data.day = pd.to_datetime(predict_data['day'], format='%Y%m%d', errors='ignore')\n",
    "predict_data = predict_data.merge(weather, left_on=['city', 'day'], right_on=['code', 'date'])\n",
    "predict_data['is_train'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "goods_counts_features = ['city', 'day', 'weather', 'temperature','wind','is_train']\n",
    "driver_counts_features = ['city', 'day', 'weather', 'temperature','wind','is_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_max_temperature(string):\n",
    "    return int(string.split('/')[0])\n",
    "def get_min_temperature(string):\n",
    "    return int(string.split('/')[1])\n",
    "def get_diff_temperature(string):\n",
    "    return int(string.split('/')[0]) - int(string.split('/')[1])\n",
    "# wind\n",
    "def get_number_wind(string):\n",
    "    pattern = re.compile(ur'\\d')\n",
    "    return max(map(int, list(pattern.findall(string))))\n",
    "def feature_engineering(goods_counts_add_weather):\n",
    "    # date\n",
    "    goods_counts_add_weather['weekday'] = goods_counts_add_weather.day.dt.weekday\n",
    "    goods_counts_add_weather['monthofday'] = goods_counts_add_weather.day.dt.day\n",
    "    # temperature\n",
    "    goods_counts_add_weather['max_temperature'] = goods_counts_add_weather.temperature.apply(get_max_temperature)\n",
    "    goods_counts_add_weather['min_temperature'] = goods_counts_add_weather.temperature.apply(get_min_temperature)\n",
    "    goods_counts_add_weather['diff_temperature'] = goods_counts_add_weather.temperature.apply(get_diff_temperature)\n",
    "    # weather\n",
    "    count_vect = CountVectorizer()\n",
    "    weather = pd.DataFrame(count_vect.fit_transform(goods_counts_add_weather[\"weather\"]).toarray(), columns=count_vect.get_feature_names())\n",
    "    goods_counts_add_weather = pd.concat([goods_counts_add_weather, weather],axis=1)\n",
    "    # wind\n",
    "    goods_counts_add_weather['wind'] = goods_counts_add_weather.wind.apply((get_number_wind))\n",
    "    # feature select\n",
    "    no_use_featuer = ['day', 'name', 'code', 'date','weather', 'temperature']\n",
    "    feature = [x for x in goods_counts_add_weather if x not in no_use_featuer]\n",
    "    return goods_counts_add_weather[feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "goods_counts_data = feature_engineering(pd.concat([goods_counts_add_weather[goods_counts_features], predict_data[goods_counts_features]], ignore_index=True))\n",
    "goods_counts_train_data = goods_counts_data[goods_counts_data.is_train==1]\n",
    "goods_counts_predict_data = goods_counts_data[goods_counts_data.is_train==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "driver_counts_data = feature_engineering(pd.concat([driver_counts_add_weather[driver_counts_features], predict_data[driver_counts_features]], ignore_index=True))\n",
    "driver_counts_train_data = driver_counts_data[driver_counts_data.is_train==1]\n",
    "driver_counts_predict_data = driver_counts_data[driver_counts_data.is_train==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## goos_counts_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "no_use_feature = ['is_train']\n",
    "features = [x for x in goods_counts_train_data.columns if x not in no_use_feature]\n",
    "train_data = goods_counts_train_data[features]\n",
    "test = goods_counts_predict_data[features]\n",
    "label = goods_counts_add_weather['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\ttraining's rmse: 129.833\tvalid_1's rmse: 278.427\n",
      "Early stopping, best iteration is:\n",
      "[999]\ttraining's rmse: 129.914\tvalid_1's rmse: 278.374\n",
      "Test RMSLE: 278.374\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[671]\ttraining's rmse: 143.493\tvalid_1's rmse: 293.003\n",
      "Test RMSLE: 293.003\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[495]\ttraining's rmse: 185.48\tvalid_1's rmse: 288.097\n",
      "Test RMSLE: 288.097\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[552]\ttraining's rmse: 171.693\tvalid_1's rmse: 301.741\n",
      "Test RMSLE: 301.741\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "\n",
    "def RMSLE(y, pred):\n",
    "    return mean_squared_error(y, pred)**0.5\n",
    "    \n",
    "\n",
    "lgb_params1 = {}\n",
    "lgb_params1['application'] = 'regression'\n",
    "lgb_params1['boosting'] = 'gbdt'\n",
    "lgb_params1['learning_rate'] = 0.015\n",
    "lgb_params1['num_leaves'] = 32\n",
    "lgb_params1['min_sum_hessian_in_leaf'] = 2e-2\n",
    "lgb_params1['min_gain_to_split'] = 0\n",
    "lgb_params1['bagging_fraction'] = 0.9\n",
    "lgb_params1['feature_fraction'] = 0.9\n",
    "lgb_params1['num_threads'] = 4\n",
    "lgb_params1['metric'] = 'rmse'\n",
    "\n",
    "lgb_params2 = {}\n",
    "lgb_params2['application'] = 'regression'\n",
    "lgb_params2['boosting'] = 'gbdt'\n",
    "lgb_params2['learning_rate'] = 0.02\n",
    "lgb_params2['lambda_l1'] = 0.5\n",
    "lgb_params2['num_leaves'] = 32\n",
    "lgb_params2['min_gain_to_split'] = 0\n",
    "lgb_params2['bagging_fraction'] = 0.8\n",
    "lgb_params2['feature_fraction'] = 0.8\n",
    "lgb_params2['num_threads'] = 4\n",
    "lgb_params2['metric'] = 'rmse'\n",
    "\n",
    "lgb_params3 = {}\n",
    "lgb_params3['application'] = 'regression'\n",
    "lgb_params3['boosting'] = 'gbdt'\n",
    "lgb_params3['learning_rate'] = 0.022\n",
    "lgb_params3['num_leaves'] = 32\n",
    "lgb_params2['lambda_l2'] = 0.3\n",
    "lgb_params3['bagging_freq'] = 8\n",
    "lgb_params3['min_gain_to_split'] = 0\n",
    "lgb_params3['bagging_fraction'] = 0.8\n",
    "lgb_params3['feature_fraction'] = 0.8\n",
    "lgb_params3['num_threads'] = 4\n",
    "lgb_params3['metric'] = 'rmse'\n",
    "\n",
    "def do_train(X_train, X_valid, y_train, y_valid, lgb_params, rounds):\n",
    "    X_t = X_train.values\n",
    "    y_t = y_train.values\n",
    "    d_train = lgb.Dataset(X_t, y_t)\n",
    "    X_v = X_valid.values\n",
    "    y_v = y_valid.values\n",
    "    d_valid = lgb.Dataset(X_v, y_v)\n",
    "    watchlist = [d_train, d_valid]\n",
    "    lgb_model = lgb.train(lgb_params, train_set=d_train, num_boost_round=rounds, \n",
    "                          valid_sets=watchlist, verbose_eval=1000, early_stopping_rounds = 300)\n",
    "    test_pred = lgb_model.predict(X_v)\n",
    "    rmsle = RMSLE(y_v, test_pred)\n",
    "#     print(X_t)\n",
    "#     print(lgb_model.feature_importance())\n",
    "    return rmsle, lgb_model\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_data, label, test_size=0.3, random_state=74)\n",
    "rmsle, lgb_model1 = do_train(X_train, X_valid, y_train, y_valid, lgb_params1, 12000)\n",
    "test_pred1 = lgb_model1.predict(test.values)\n",
    "print('Test RMSLE: %.3f' % rmsle)\n",
    "    \n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_data, label, test_size=0.3, random_state=2121)\n",
    "rmsle, lgb_model2 = do_train(X_train, X_valid, y_train, y_valid, lgb_params2, 10000)\n",
    "test_pred2 = lgb_model2.predict(test.values)\n",
    "print('Test RMSLE: %.3f' % rmsle)   \n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_data, label, test_size=0.3, random_state=4)\n",
    "rmsle, lgb_model3 = do_train(X_train, X_valid, y_train, y_valid, lgb_params3, 8000)\n",
    "test_pred3 = lgb_model3.predict(test.values)\n",
    "print('Test RMSLE: %.3f' % rmsle)   \n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_data, label, test_size=0.3, random_state=19)\n",
    "rmsle, lgb_model4 = do_train(X_train, X_valid, y_train, y_valid, lgb_params3, 8000)\n",
    "test_pred4 = lgb_model4.predict(test.values)\n",
    "print('Test RMSLE: %.3f' % rmsle)  \n",
    "\n",
    "#test_pred = (test_pred3 + test_pred4) / 2\n",
    "test_pred = (test_pred1 + test_pred2 + test_pred3 + test_pred4) / 4\n",
    "# result.to_csv('LGB_sub.csv', index=False)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit = pd.read_csv(predict_dir_path + 'sample.csv')\n",
    "submit['cargo_count'] = test_pred.astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## driver_call_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "no_use_feature = ['is_train']\n",
    "features = [x for x in driver_counts_train_data.columns if x not in no_use_feature]\n",
    "train_data = driver_counts_train_data[features]\n",
    "test = driver_counts_predict_data[features]\n",
    "label = driver_counts_add_weather['driver_call_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\ttraining's rmse: 400.447\tvalid_1's rmse: 820.132\n",
      "Early stopping, best iteration is:\n",
      "[868]\ttraining's rmse: 432.446\tvalid_1's rmse: 818.738\n",
      "Test RMSLE: 818.738\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\ttraining's rmse: 337.394\tvalid_1's rmse: 940.287\n",
      "Early stopping, best iteration is:\n",
      "[1072]\ttraining's rmse: 322.271\tvalid_1's rmse: 939.306\n",
      "Test RMSLE: 939.306\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\ttraining's rmse: 389.496\tvalid_1's rmse: 894.816\n",
      "Early stopping, best iteration is:\n",
      "[782]\ttraining's rmse: 445.876\tvalid_1's rmse: 891.434\n",
      "Test RMSLE: 891.434\n",
      "Training until validation scores don't improve for 300 rounds.\n",
      "[1000]\ttraining's rmse: 353.635\tvalid_1's rmse: 1012.68\n",
      "Early stopping, best iteration is:\n",
      "[1146]\ttraining's rmse: 322.632\tvalid_1's rmse: 1006.96\n",
      "Test RMSLE: 1006.956\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "\n",
    "def RMSLE(y, pred):\n",
    "    return mean_squared_error(y, pred)**0.5\n",
    "\n",
    "lgb_params1 = {}\n",
    "lgb_params1['application'] = 'regression'\n",
    "lgb_params1['boosting'] = 'gbdt'\n",
    "lgb_params1['learning_rate'] = 0.015\n",
    "lgb_params1['num_leaves'] = 32\n",
    "lgb_params1['min_sum_hessian_in_leaf'] = 2e-2\n",
    "lgb_params1['min_gain_to_split'] = 0\n",
    "lgb_params1['bagging_fraction'] = 0.9\n",
    "lgb_params1['feature_fraction'] = 0.9\n",
    "lgb_params1['num_threads'] = 4\n",
    "lgb_params1['metric'] = 'rmse'\n",
    "\n",
    "lgb_params2 = {}\n",
    "lgb_params2['application'] = 'regression'\n",
    "lgb_params2['boosting'] = 'gbdt'\n",
    "lgb_params2['learning_rate'] = 0.02\n",
    "lgb_params2['lambda_l1'] = 0.5\n",
    "lgb_params2['num_leaves'] = 32\n",
    "lgb_params2['min_gain_to_split'] = 0\n",
    "lgb_params2['bagging_fraction'] = 0.8\n",
    "lgb_params2['feature_fraction'] = 0.8\n",
    "lgb_params2['num_threads'] = 4\n",
    "lgb_params2['metric'] = 'rmse'\n",
    "\n",
    "lgb_params3 = {}\n",
    "lgb_params3['application'] = 'regression'\n",
    "lgb_params3['boosting'] = 'gbdt'\n",
    "lgb_params3['learning_rate'] = 0.022\n",
    "lgb_params3['num_leaves'] = 32\n",
    "lgb_params2['lambda_l2'] = 0.3\n",
    "lgb_params3['bagging_freq'] = 8\n",
    "lgb_params3['min_gain_to_split'] = 0\n",
    "lgb_params3['bagging_fraction'] = 0.8\n",
    "lgb_params3['feature_fraction'] = 0.8\n",
    "lgb_params3['num_threads'] = 4\n",
    "lgb_params3['metric'] = 'rmse'\n",
    "\n",
    "def do_train(X_train, X_valid, y_train, y_valid, lgb_params, rounds):\n",
    "    X_t = X_train.values\n",
    "    y_t = y_train.values\n",
    "    d_train = lgb.Dataset(X_t, y_t)\n",
    "    X_v = X_valid.values\n",
    "    y_v = y_valid.values\n",
    "    d_valid = lgb.Dataset(X_v, y_v)\n",
    "    watchlist = [d_train, d_valid]\n",
    "    lgb_model = lgb.train(lgb_params, train_set=d_train, num_boost_round=rounds, \n",
    "                          valid_sets=watchlist, verbose_eval=1000, early_stopping_rounds = 300)\n",
    "    test_pred = lgb_model.predict(X_v)\n",
    "    rmsle = RMSLE(y_v, test_pred)\n",
    "#     print(X_t)\n",
    "#     print(lgb_model.feature_importance())\n",
    "    return rmsle, lgb_model\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_data, label, test_size=0.3, random_state=74)\n",
    "rmsle, lgb_model1 = do_train(X_train, X_valid, y_train, y_valid, lgb_params1, 12000)\n",
    "test_pred1 = lgb_model1.predict(test.values)\n",
    "print('Test RMSLE: %.3f' % rmsle)\n",
    "    \n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_data, label, test_size=0.3, random_state=2121)\n",
    "rmsle, lgb_model2 = do_train(X_train, X_valid, y_train, y_valid, lgb_params2, 10000)\n",
    "test_pred2 = lgb_model2.predict(test.values)\n",
    "print('Test RMSLE: %.3f' % rmsle)   \n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_data, label, test_size=0.3, random_state=4)\n",
    "rmsle, lgb_model3 = do_train(X_train, X_valid, y_train, y_valid, lgb_params3, 8000)\n",
    "test_pred3 = lgb_model3.predict(test.values)\n",
    "print('Test RMSLE: %.3f' % rmsle)   \n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_data, label, test_size=0.3, random_state=19)\n",
    "rmsle, lgb_model4 = do_train(X_train, X_valid, y_train, y_valid, lgb_params3, 8000)\n",
    "test_pred4 = lgb_model4.predict(test.values)\n",
    "print('Test RMSLE: %.3f' % rmsle)  \n",
    "\n",
    "#test_pred = (test_pred3 + test_pred4) / 2\n",
    "test_pred = (test_pred1 + test_pred2 + test_pred3 + test_pred4) / 4\n",
    "# result.to_csv('LGB_sub.csv', index=False)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['driver_call_count'] = test_pred.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('submit07101052.csv', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
